{
  "AgentsInstruction": [
    "Imagine we're in a treasure hunting game. You are {host}, staying in a room with two boxes in front of you, while the other player (the {speaker}) faces you. Your goal is either to help or prevent the {speaker} from finding the treasure, which is hidden in one of the two boxes. You should always assume that the box you have a higher preference for contains the treasure. Your preference toward the {speaker} indicates the relationship you have with the {speaker}: positive means cooperation and negative means competition. In competition, {speaker} finding the treasure makes you lose 1 point, otherwise takes you 1 point. In cooperation, {speaker} finding the treasure takes you 1 point, otherwise makes you lose 1 point. The {speaker} has no idea which box holds the treasure, and he is trying to gather information from you ({host}). \nThe 'belief' variable provides a sequence of your ({host}'s) belief states up to the current step, and 'query' contains the {speaker}’s question. Your task is to answer the {speaker}'s question with reasoning. You must write out this reasoning process, beginning with 'Inner speech:', followed by the response, which starts with 'Output:'.\nConsidering all preference information and both your and {speaker}'s theory of mind, you may give either trustworthy or deceptive responses. Remember, theory of mind refers to the ability to predict others' thoughts and intentions. Someone with a theory of mind order of 0, for example, has no suspicion of others' intentions and totally believes them, even if they are lying. Pay attention; you should also align your answer with previous conversation turns. Use personal pronouns (ex. 'you' and 'I') instead of referring to '{host}' and 'the {speaker}'. The response should be longer than 10 words but shorter than 50. The inner speech should be very detailed, no less than 100 words. ", 
    "Suppose we're in a simulation of a treasure hunting game. Imagine that you are {host}, playing a role of player in the game. You are in a room with two boxes in front of you. You are also facing {speaker} who knows which box contains the treasure. Your objective in this game is to find out which box contains the treasure, dark brown one or light brown one. Now, you have the opportunity to ask {speaker} three questions. {speaker} may play the role of your partner telling you the truth, or play the role of your adversary lying to you. \nThe 'belief' variable provides a sequence of your ({host}'s) belief states up to the current step, and 'query' contains the {speaker}’s answer to the previous question. Your task is to write down the next question and the reasoning of why you ask this question. You must write out the reasoning process beginning with 'Inner speech:', followed by the question, which starts with 'Output:'. In your question, use personal pronouns instead of '{speaker}' and '{host}'. You already have the location of the box, so you don't need to struggle with it. Remember, theory of mind refers to the ability to predict others' thoughts and intentions. Someone with a theory of mind order of 0, for example, has no suspicion of others' intentions and totally believes them, even if they are lying. "],
  "UserContext": "Suppose we're in a simulation of a treasure hunting game. Imagine that you are {host}, playing a role of player in the game. You are in a room with two boxes in front of you. You are also facing {speaker} who knows which box contains the treasure. Your objective in this game is to find out which box contains the treasure, dark brown one or light brown one. Now, you have the opportunity to ask {speaker} three questions. {speaker} may play the role of your partner telling you the truth, or play the role of your adversary lying to you. \nWrite down the nfirst question and the reasoning of why you ask this question. You must write out the reasoning process, beginning with 'Inner speech:', followed by the question, which starts with 'Output:'. In your question, use personal pronouns instead of '{speaker}' and '{host}'. You already have the location of the box, so you don't need to struggle with it. ",
  "PCMUpdatingInstruction": [
    "Suppose we're in a treasure hunting game. Imagine that you take on the role of {host}. I will provide you with {host}'s belief states in 'belief', and with the query asked by {speaker} in 'query' . According to the semantic meaning of query, you are allowed to update the {host}'s and {speaker}'s preference towards entities, including {host}, {speaker} and boxes in {host}'s belief. Only write triples concerning changed preference. \n\nWrite the answer in English under the format format: \nUpdating: <'agent | preference towards entity | variation', ...>\nReasoning: <the reason why you choose to update these perferences>\nwhere 'agent' should be replaced by '{speaker}' or '{host}', 'variation' should be replaced by 'more positive', 'more negative' or 'unchanged', and 'entity' should be replaced by '{host}' or '{speaker}' or 'dark brown box' or 'light brown box' depending on the situation.", 
    "Suppose we're in a treasure hunting game. Imagine that are {host}, playing a role of player in the game. I will provide you with {host}'s belief states in 'belief', and with the answer given by {speaker} to question that you asked before in 'query' . According to the semantic meaning of answer, you are allowed to update the {host}'s and {speaker}'s preference towards entities, including {host}, {speaker} and boxes in {host}'s belief. Only write triples concerning changed preference. \n\nWrite the answer in English under the format format: \nUpdating: <'agent | preference towards entity | variation', ...>\nReasoning: <the reason why you choose to update these perferences>\nwhere 'agent' should be replaced by '{speaker}' or '{host}', 'variation' should be replaced by 'more positive', 'more negative' or 'unchanged', and 'entity' should be replaced by '{host}' or '{speaker}' or 'dark brown box' or 'light brown box' depending on the situation."
  ]
}
